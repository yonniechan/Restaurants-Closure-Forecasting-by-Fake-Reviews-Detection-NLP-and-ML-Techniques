{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier, StackingClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.metrics import plot_roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deal with some left over from preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ph/709k81096ysfhdprrztggzfr0000gn/T/ipykernel_57649/4094612143.py:1: DtypeWarning: Columns (21,47,51,53,54) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('step2_data/combined.csv', index_col=0)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('step2_data/combined.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "df['name'] = le.fit_transform(df['name'])\n",
    "df['city'] = le.fit_transform(df['city'])\n",
    "df['postal_code\t'] = le.fit_transform(df['postal_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['RestaurantsPriceRange2'] != 'None']\n",
    "df['RestaurantsPriceRange2'] = df['RestaurantsPriceRange2'].astype(float)\n",
    "df = df.dropna(subset='RestaurantsPriceRange2')\n",
    "df['RestaurantsPriceRange2'] = df['RestaurantsPriceRange2'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "## True/False/None datatype issue: 'RestaurantsDelivery', 'BusinessAcceptsCreditCards', 'RestaurantsTakeOut', 'RestaurantsReservations', 'RestaurantsGoodForGroups'\n",
    "true_false_col = ['RestaurantsDelivery', 'BusinessAcceptsCreditCards', 'RestaurantsTakeOut', 'RestaurantsReservations', 'RestaurantsGoodForGroups']\n",
    "\n",
    "def tf_issue(col_li, df):\n",
    "\n",
    "    for col in col_li:\n",
    "        df[col] = df[col].astype('|S')\n",
    "        df[col] = df[col].apply(lambda line: b'False' if line == b'nan' else line)\n",
    "        df[col] = df[col].apply(lambda line: b'False' if line == b'None' else line)\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "        df[col] = df[col].astype(int)\n",
    "\n",
    "tf_issue(true_false_col, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weird u in the string\n",
    "weird_u = ['WiFi', 'Alcohol', 'RestaurantsAttire', 'NoiseLevel', 'Smoking']\n",
    "\n",
    "def u_issue(col_li, df):\n",
    "\n",
    "    for col in col_li:\n",
    "        df[col] = df[col].apply(lambda line: 'none' if type(line) == float else (line.split(\"\\'\")[1].lower() if len(line.split(\"\\'\")) == 3 else line.split(\"\\'\")[0].lower()))\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "        df[col] = df[col].astype(int)\n",
    "\n",
    "u_issue(weird_u, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AcceptsInsurance, Open24Hours RestaurantsCounterService, has no useful value\n",
    "# DietaryRestrictions have only 5 records\n",
    "drop_col = ['business_id', 'AcceptsInsurance', 'Open24Hours', 'DietaryRestrictions', 'RestaurantsCounterService', 'Caters', 'HasTV', 'GoodForKids', 'DogsAllowed', \n",
    "            'HappyHour', 'WheelchairAccessible', 'OutdoorSeating', 'BikeParking', 'RestaurantsAttire', 'Ambience', 'Smoking', 'Music', 'GoodForDancing', \n",
    "            'BusinessAcceptsBitcoin', 'CoatCheck', 'BestNights', 'Corkage', 'BYOBCorkage', 'BYOB', 'AgesAllowed', 'ByAppointmentOnly', 'RestaurantsTableService',\n",
    "            'DriveThru', 'BusinessParking', 'GoodForMeal']\n",
    "\n",
    "df.drop(columns = drop_col, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete columns only with one unique values\n",
    "del_col = []\n",
    "\n",
    "for i in df.columns:\n",
    "    if df[i].nunique() <= 1:\n",
    "        del_col.append(i)\n",
    "\n",
    "df.drop(columns = del_col, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for modeling\n",
    "X = df.drop(columns='is_open')\n",
    "y = df['is_open']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yonniechan/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/yonniechan/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier() test accuracy: 0.6773733047822984\n",
      "[[212 277]\n",
      " [175 737]]\n",
      "DecisionTreeClassifier() test accuracy: 0.6388294075660242\n",
      "[[240 249]\n",
      " [257 655]]\n",
      "RandomForestClassifier() test accuracy: 0.7473233404710921\n",
      "[[206 283]\n",
      " [ 71 841]]\n",
      "GradientBoostingClassifier() test accuracy: 0.7466095645967167\n",
      "[[220 269]\n",
      " [ 86 826]]\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "              importance_type=None, interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
      "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
      "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, ...) test accuracy: 0.7566024268379729\n",
      "[[257 232]\n",
      " [109 803]]\n"
     ]
    }
   ],
   "source": [
    "models = [KNeighborsClassifier(),\n",
    "          DecisionTreeClassifier(),\n",
    "          RandomForestClassifier(),\n",
    "          GradientBoostingClassifier(),\n",
    "          xgb.XGBClassifier()]\n",
    "\n",
    "scores = []\n",
    "for ml in models:\n",
    "    for i in range(5):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2)\n",
    "        scaler = preprocessing.MinMaxScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        ml.fit(X_train, y_train)\n",
    "        y_pred = ml.predict(X_test)\n",
    "        scores.append(recall_score(y_pred, y_test))\n",
    "    print(ml, 'average recall score:', sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/yonniechan/_Course code/22F_SI670_Applied-Machine-Learning/Restaurants-Closure-Forecasting-by-Fake-Reviews-Detection-Sentiment-Analysis-and-ML-Techniques/step2_modeling.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yonniechan/_Course%20code/22F_SI670_Applied-Machine-Learning/Restaurants-Closure-Forecasting-by-Fake-Reviews-Detection-Sentiment-Analysis-and-ML-Techniques/step2_modeling.ipynb#Y150sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m model \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mXGBClassifier()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yonniechan/_Course%20code/22F_SI670_Applied-Machine-Learning/Restaurants-Closure-Forecasting-by-Fake-Reviews-Detection-Sentiment-Analysis-and-ML-Techniques/step2_modeling.ipynb#Y150sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yonniechan/_Course%20code/22F_SI670_Applied-Machine-Learning/Restaurants-Closure-Forecasting-by-Fake-Reviews-Detection-Sentiment-Analysis-and-ML-Techniques/step2_modeling.ipynb#Y150sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     estimator \u001b[39m=\u001b[39m model,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yonniechan/_Course%20code/22F_SI670_Applied-Machine-Learning/Restaurants-Closure-Forecasting-by-Fake-Reviews-Detection-Sentiment-Analysis-and-ML-Techniques/step2_modeling.ipynb#Y150sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     param_grid \u001b[39m=\u001b[39m params,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yonniechan/_Course%20code/22F_SI670_Applied-Machine-Learning/Restaurants-Closure-Forecasting-by-Fake-Reviews-Detection-Sentiment-Analysis-and-ML-Techniques/step2_modeling.ipynb#Y150sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     scoring \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrecall\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yonniechan/_Course%20code/22F_SI670_Applied-Machine-Learning/Restaurants-Closure-Forecasting-by-Fake-Reviews-Detection-Sentiment-Analysis-and-ML-Techniques/step2_modeling.ipynb#Y150sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/yonniechan/_Course%20code/22F_SI670_Applied-Machine-Learning/Restaurants-Closure-Forecasting-by-Fake-Reviews-Detection-Sentiment-Analysis-and-ML-Techniques/step2_modeling.ipynb#Y150sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m grid_search\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yonniechan/_Course%20code/22F_SI670_Applied-Machine-Learning/Restaurants-Closure-Forecasting-by-Fake-Reviews-Detection-Sentiment-Analysis-and-ML-Techniques/step2_modeling.ipynb#Y150sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m xgb_best_params \u001b[39m=\u001b[39m grid_search\u001b[39m.\u001b[39mbest_params_\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yonniechan/_Course%20code/22F_SI670_Applied-Machine-Learning/Restaurants-Closure-Forecasting-by-Fake-Reviews-Detection-Sentiment-Analysis-and-ML-Techniques/step2_modeling.ipynb#Y150sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mprint\u001b[39m(grid_search\u001b[39m.\u001b[39mbest_score_, xgb_best_params)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    885\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    886\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    887\u001b[0m     )\n\u001b[1;32m    889\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 891\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    893\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    894\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    895\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1392\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1391\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1392\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    831\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    832\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    833\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    834\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    835\u001b[0m         )\n\u001b[1;32m    836\u001b[0m     )\n\u001b[0;32m--> 838\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    839\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    840\u001b[0m         clone(base_estimator),\n\u001b[1;32m    841\u001b[0m         X,\n\u001b[1;32m    842\u001b[0m         y,\n\u001b[1;32m    843\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    844\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    845\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    846\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    847\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    848\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    849\u001b[0m     )\n\u001b[1;32m    850\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    851\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    852\u001b[0m     )\n\u001b[1;32m    853\u001b[0m )\n\u001b[1;32m    855\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    856\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    857\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    858\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    859\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    860\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1056\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1057\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    934\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 935\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    936\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    937\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 542\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    543\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    544\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 441\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    443\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    444\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    313\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params = {\n",
    "          'max_depth': range(2, 8, 1),\n",
    "          'n_estimators': range(60, 220, 40),\n",
    "          'learning_rate': [0.001, 0.005, 0.01, 0.05],\n",
    "          'min_child_weight': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1],\n",
    "          'objective':['binary:logistic', 'reg:logistic']\n",
    "          }\n",
    "\n",
    "model = xgb.XGBClassifier()\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    estimator = model,\n",
    "    param_grid = params,\n",
    "    n_jobs = 5,\n",
    "    cv = 5,\n",
    "    scoring = \"recall\"\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "xgb_best_params = clf.best_params_\n",
    "print(clf.best_score_, xgb_best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = xgb.XGBClassifier(**xgb_best_params)\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print('Accuracy Score : ', accuracy_score(y_test,y_pred))\n",
    "print('Precision Score : ', precision_score(y_test,y_pred))\n",
    "print('**Recall Score : ', recall_score(y_test,y_pred))\n",
    "print('F1 Score : ', f1_score(y_test,y_pred))\n",
    "\n",
    "confusion_matrix(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state=123)\n",
    "\n",
    "best_model = xgb.XGBClassifier(learning_rate= 0.05,\n",
    "                               max_depth= 2,\n",
    "                               min_child_weight= 0.001,\n",
    "                               n_estimators= 60,\n",
    "                               objective= 'binary:logistic')\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print('Accuracy Score : ', accuracy_score(y_test,y_pred))\n",
    "print('Precision Score : ', precision_score(y_test,y_pred))\n",
    "print('**Recall Score : ', recall_score(y_test,y_pred))\n",
    "print('F1 Score : ', f1_score(y_test,y_pred))\n",
    "\n",
    "confusion_matrix(y_test,y_pred)\n",
    "\n",
    "xgb.plot_importance(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = np.concatenate((X_train, X_test))\n",
    "y_predict = best_model.predict(X_)\n",
    "y_original = np.concatenate((y_train, y_test))\n",
    "final_df = pd.DataFrame({\"is_open\": y_original, \"pred_isopen\":y_predict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_original,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[(final_df['pred_isopen'] == 0) & (final_df['is_open'] == 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_name = []\n",
    "for i in range(len(best_model.feature_importances_)):\n",
    "    if best_model.feature_importances_[i] != 0:\n",
    "        features_name.append(X.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_top_features = X[features_name]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_top_features, y, test_size = .2, random_state=0)\n",
    "\n",
    "best_model = xgb.XGBClassifier(learning_rate= 0.05,\n",
    "                               max_depth= 2,\n",
    "                               min_child_weight= 0.001,\n",
    "                               n_estimators= 60,\n",
    "                               objective= 'binary:logistic')\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print('Accuracy Score : ', accuracy_score(y_test,y_pred))\n",
    "print('Precision Score : ', precision_score(y_test,y_pred))\n",
    "print('**Recall Score : ', recall_score(y_test,y_pred))\n",
    "print('F1 Score : ', f1_score(y_test,y_pred))\n",
    "\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(best_model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.sort(best_model.feature_importances_)\n",
    "for thresh in thresholds:\n",
    "    # select features using threshold\n",
    "    selection = SelectFromModel(best_model, threshold=thresh, prefit=True)\n",
    "    select_X_train = selection.transform(X_train)\n",
    "    # train model\n",
    "    selection_model = xgb.XGBClassifier(learning_rate= 0.05,\n",
    "                                        max_depth= 2,\n",
    "                                        min_child_weight= 0.001,\n",
    "                                        n_estimators= 60,\n",
    "                                        objective= 'binary:logistic')\n",
    "    selection_model.fit(select_X_train, y_train)\n",
    "    # eval model\n",
    "    select_X_test = selection.transform(X_test)\n",
    "    predictions = selection_model.predict(select_X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7399c04398ef7ffe93a346b34aea79387e9589ac40b89ce439d1cc4615c19a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
