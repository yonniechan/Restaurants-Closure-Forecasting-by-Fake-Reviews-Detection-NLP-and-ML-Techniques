{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from textblob import TextBlob\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = open(\"data/yelp_academic_dataset_review.json\")\n",
    "reviews_data = []\n",
    "c = 0\n",
    "for line in data_file:\n",
    "    reviews_data.append(json.loads(line))\n",
    "    c+=1\n",
    "    if c == 100000:\n",
    "        break\n",
    "\n",
    "reviews_df = pd.DataFrame(reviews_data)\n",
    "\n",
    "data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = open(\"data/yelp_academic_dataset_business.json\")\n",
    "business_data = []\n",
    "\n",
    "for line in data_file:\n",
    "    business_data.append(json.loads(line))\n",
    "\n",
    "business_df = pd.DataFrame(business_data)\n",
    "\n",
    "data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6942</th>\n",
       "      <td>TYslH-CAecjJxLNs96KduA</td>\n",
       "      <td>XCsZ3hWa_6oP1WkWvK7pmg</td>\n",
       "      <td>29YqJwOGEuAWqlHZxMc1OA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Lovely little restaurant which was converted f...</td>\n",
       "      <td>2005-03-01 17:47:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5943</th>\n",
       "      <td>qU51pK9Ui3pG5phxzUKtyA</td>\n",
       "      <td>58yhbFfNHjULDZx0FD-Dvw</td>\n",
       "      <td>xwKYBPO0ByGlkvNcr8FdqQ</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Romantic and cozy French restaurant. A bit pri...</td>\n",
       "      <td>2005-03-09 06:37:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5471</th>\n",
       "      <td>bpraoKKp9AbNYbm1M6113A</td>\n",
       "      <td>58yhbFfNHjULDZx0FD-Dvw</td>\n",
       "      <td>B10mqANgHvL8gBteo1UhAA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>My favorite Italian restaurant in Tucson. Fami...</td>\n",
       "      <td>2005-03-09 07:23:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756</th>\n",
       "      <td>QTE44bHheG6ugQU4em4SdQ</td>\n",
       "      <td>B6FbaEEn5Uh4kEqv4kUdgA</td>\n",
       "      <td>f82dhKNiUXsDVPMLqKYiIQ</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>OK lunch buffet, but too oily.  i think weeken...</td>\n",
       "      <td>2005-03-12 03:47:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4689</th>\n",
       "      <td>ocPjTgIqZJaCnVehOaPmEQ</td>\n",
       "      <td>9Z2UEd_f6eC17YxifpWfMw</td>\n",
       "      <td>7n-8nhFq266slKmHJEY1-Q</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ya wanna get crunked? No problem, buy a 16oz o...</td>\n",
       "      <td>2005-03-14 23:43:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5849</th>\n",
       "      <td>N0SEpi3lSDOMmNdjctk87Q</td>\n",
       "      <td>fCDCgLpxnflyE5LlFtSkEA</td>\n",
       "      <td>ErpOHBaOcmZjnBw0EutQJg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>They have the best bagels in town! I have been...</td>\n",
       "      <td>2018-10-04 17:53:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3011</th>\n",
       "      <td>hG0cjaWBeZ2sUKRHr5HSyA</td>\n",
       "      <td>WqbcV5y-yz1SNfdLZEYrvA</td>\n",
       "      <td>aKOdfQcjDG2NQtIEmq21ew</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>awesome place!!!! very dope setting large part...</td>\n",
       "      <td>2018-10-04 18:03:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2423</th>\n",
       "      <td>v-K341pe1rxU_FtM_ubksQ</td>\n",
       "      <td>YIEafQT5RbTFbG8SnyO4LQ</td>\n",
       "      <td>fpQEKdtFprof-RJx1MRR9g</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Locations at both Ina Rd and Oracle Rd have eq...</td>\n",
       "      <td>2018-10-04 18:10:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8933</th>\n",
       "      <td>o0Jm0ALfZJp2JaX7sBv0Yg</td>\n",
       "      <td>jheopFKRPEDAR_ur5HGTug</td>\n",
       "      <td>pSmOH4a3HNNpYM82J5ycLA</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Went with a large group and the service was de...</td>\n",
       "      <td>2018-10-04 18:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6615</th>\n",
       "      <td>EC05bAyjEMumJ_CXLLzD3Q</td>\n",
       "      <td>bak-LF0-gUmYBg6_575njg</td>\n",
       "      <td>1oa1vyzmOFPUyy11uDiw6w</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>We've gone to several different vets at Kirkwo...</td>\n",
       "      <td>2018-10-04 18:22:35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   review_id                 user_id             business_id  \\\n",
       "6942  TYslH-CAecjJxLNs96KduA  XCsZ3hWa_6oP1WkWvK7pmg  29YqJwOGEuAWqlHZxMc1OA   \n",
       "5943  qU51pK9Ui3pG5phxzUKtyA  58yhbFfNHjULDZx0FD-Dvw  xwKYBPO0ByGlkvNcr8FdqQ   \n",
       "5471  bpraoKKp9AbNYbm1M6113A  58yhbFfNHjULDZx0FD-Dvw  B10mqANgHvL8gBteo1UhAA   \n",
       "2756  QTE44bHheG6ugQU4em4SdQ  B6FbaEEn5Uh4kEqv4kUdgA  f82dhKNiUXsDVPMLqKYiIQ   \n",
       "4689  ocPjTgIqZJaCnVehOaPmEQ  9Z2UEd_f6eC17YxifpWfMw  7n-8nhFq266slKmHJEY1-Q   \n",
       "...                      ...                     ...                     ...   \n",
       "5849  N0SEpi3lSDOMmNdjctk87Q  fCDCgLpxnflyE5LlFtSkEA  ErpOHBaOcmZjnBw0EutQJg   \n",
       "3011  hG0cjaWBeZ2sUKRHr5HSyA  WqbcV5y-yz1SNfdLZEYrvA  aKOdfQcjDG2NQtIEmq21ew   \n",
       "2423  v-K341pe1rxU_FtM_ubksQ  YIEafQT5RbTFbG8SnyO4LQ  fpQEKdtFprof-RJx1MRR9g   \n",
       "8933  o0Jm0ALfZJp2JaX7sBv0Yg  jheopFKRPEDAR_ur5HGTug  pSmOH4a3HNNpYM82J5ycLA   \n",
       "6615  EC05bAyjEMumJ_CXLLzD3Q  bak-LF0-gUmYBg6_575njg  1oa1vyzmOFPUyy11uDiw6w   \n",
       "\n",
       "      stars  useful  funny  cool  \\\n",
       "6942    5.0       0      0     0   \n",
       "5943    4.0       0      0     0   \n",
       "5471    5.0       0      0     0   \n",
       "2756    3.0       0      0     0   \n",
       "4689    3.0       1      0     0   \n",
       "...     ...     ...    ...   ...   \n",
       "5849    5.0       0      0     0   \n",
       "3011    5.0       0      0     0   \n",
       "2423    1.0       0      0     0   \n",
       "8933    3.0       0      0     0   \n",
       "6615    5.0       0      0     0   \n",
       "\n",
       "                                                   text                 date  \n",
       "6942  Lovely little restaurant which was converted f...  2005-03-01 17:47:15  \n",
       "5943  Romantic and cozy French restaurant. A bit pri...  2005-03-09 06:37:47  \n",
       "5471  My favorite Italian restaurant in Tucson. Fami...  2005-03-09 07:23:26  \n",
       "2756  OK lunch buffet, but too oily.  i think weeken...  2005-03-12 03:47:06  \n",
       "4689  ya wanna get crunked? No problem, buy a 16oz o...  2005-03-14 23:43:07  \n",
       "...                                                 ...                  ...  \n",
       "5849  They have the best bagels in town! I have been...  2018-10-04 17:53:48  \n",
       "3011  awesome place!!!! very dope setting large part...  2018-10-04 18:03:09  \n",
       "2423  Locations at both Ina Rd and Oracle Rd have eq...  2018-10-04 18:10:01  \n",
       "8933  Went with a large group and the service was de...  2018-10-04 18:20:00  \n",
       "6615  We've gone to several different vets at Kirkwo...  2018-10-04 18:22:35  \n",
       "\n",
       "[100000 rows x 9 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.sort_values('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out reviews for restaurants not in PA \n",
    "business_list = business_df[business_df['state']=='PA']['business_id']\n",
    "df = reviews_df[reviews_df['business_id'].isin(business_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ph/709k81096ysfhdprrztggzfr0000gn/T/ipykernel_94901/789486673.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['date'] =  pd.to_datetime(df['date'], format='%Y-%m-%d %H:%M:%S')\n",
      "/var/folders/ph/709k81096ysfhdprrztggzfr0000gn/T/ipykernel_94901/789486673.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['year'] = pd.DatetimeIndex(df['date']).year\n",
      "/var/folders/ph/709k81096ysfhdprrztggzfr0000gn/T/ipykernel_94901/789486673.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['month'] = pd.DatetimeIndex(df['date']).month\n",
      "/var/folders/ph/709k81096ysfhdprrztggzfr0000gn/T/ipykernel_94901/789486673.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['day'] = pd.DatetimeIndex(df['date']).day\n",
      "/var/folders/ph/709k81096ysfhdprrztggzfr0000gn/T/ipykernel_94901/789486673.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['hour'] = pd.DatetimeIndex(df['date']).hour\n",
      "/var/folders/ph/709k81096ysfhdprrztggzfr0000gn/T/ipykernel_94901/789486673.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['min'] = pd.DatetimeIndex(df['date']).minute\n",
      "/var/folders/ph/709k81096ysfhdprrztggzfr0000gn/T/ipykernel_94901/789486673.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sec'] = pd.DatetimeIndex(df['date']).second\n"
     ]
    }
   ],
   "source": [
    "def split_time_to_feature(df):\n",
    "\n",
    "    df['date'] =  pd.to_datetime(df['date'], format='%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    df['year'] = pd.DatetimeIndex(df['date']).year\n",
    "    df['month'] = pd.DatetimeIndex(df['date']).month\n",
    "    df['day'] = pd.DatetimeIndex(df['date']).day\n",
    "    df['hour'] = pd.DatetimeIndex(df['date']).hour\n",
    "    df['min'] = pd.DatetimeIndex(df['date']).minute\n",
    "    df['sec'] = pd.DatetimeIndex(df['date']).second\n",
    "\n",
    "split_time_to_feature(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract reivews left in 2000-2018\n",
    "df = df.loc[(df['year'] >= 2000) & (df['year'] <= 2018)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new column in the dataset for the length of the reviews\n",
    "df['length_of_reviews'] = df['text'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new column in the dataset for the number of words in the reviews\n",
    "df['num_of_words'] = df['text'].apply(lambda str:len(nltk.word_tokenize(str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new column in the dataset for the number of sentences in the reviews\n",
    "df['num_of_sentences'] = df['text'].apply(lambda paragraph:len(nltk.sent_tokenize(paragraph)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['capital_words'] = df['text'].apply(lambda sen:len(re.findall(r'\\b[A-Z]+\\b', sen)))\n",
    "df['capital_words_ratio'] = df['capital_words']/df['num_of_words']\n",
    "df.drop(columns='capital_words', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with texts in reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the reviews - stemed, remove stopwords and punctuation\n",
    "def clean_text(text):\n",
    "\n",
    "    ## Remove puncuation\n",
    "    nopunc = [char for char in text if char not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    ## Remove stop words\n",
    "    nostop = [word for word in nopunc.split() if word.lower() not in stopwords.words('english') and len(word) >= 3]\n",
    "    text = ' '.join(nostop)\n",
    "   \n",
    "    # Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)    \n",
    "    \n",
    "    ps = PorterStemmer()\n",
    "    text = ps.stem(text)\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = lemmatizer.lemmatize(text)\n",
    "\n",
    "    return text\n",
    "\n",
    "df['cleaned_text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment analysis using textblob \n",
    "df['sentiment_polarity'] = df['cleaned_text'].apply(lambda w:TextBlob(w).polarity)\n",
    "df['sentiment_subjectivity'] = df['cleaned_text'].apply(lambda w:TextBlob(w).subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/cleaned_review_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>...</th>\n",
       "      <th>hour</th>\n",
       "      <th>min</th>\n",
       "      <th>sec</th>\n",
       "      <th>length_of_reviews</th>\n",
       "      <th>num_of_words</th>\n",
       "      <th>num_of_sentences</th>\n",
       "      <th>capital_words_ratio</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "      <th>sentiment_subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KU_O5udG6zpxOg-VcAEodg</td>\n",
       "      <td>mh_-eMZ6K5RLWhZyISBhwA</td>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>If you decide to eat here, just be aware it is...</td>\n",
       "      <td>2018-07-07 22:09:11</td>\n",
       "      <td>2018</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>513</td>\n",
       "      <td>114</td>\n",
       "      <td>7</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>decide eat aware going take hours beginning en...</td>\n",
       "      <td>0.209722</td>\n",
       "      <td>0.419444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BiTunyQ73aT9WBnpR9DZGw</td>\n",
       "      <td>OyoGAe7OKpv6SyGZT5g77Q</td>\n",
       "      <td>7ATYjTIgM3jUlt4UM3IypQ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I've taken a lot of spin classes over the year...</td>\n",
       "      <td>2012-01-03 15:28:18</td>\n",
       "      <td>2012</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>18</td>\n",
       "      <td>829</td>\n",
       "      <td>174</td>\n",
       "      <td>7</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>ive taken lot spin classes years nothing compa...</td>\n",
       "      <td>0.395455</td>\n",
       "      <td>0.571212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AqPFMleE6RsU23_auESxiA</td>\n",
       "      <td>_7bHUi9Uuf5__HHc_Q8guQ</td>\n",
       "      <td>kxX2SOes4o-D3ZQBkiMRfA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Wow!  Yummy, different,  delicious.   Our favo...</td>\n",
       "      <td>2015-01-04 00:01:03</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>243</td>\n",
       "      <td>56</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>wow yummy different delicious favorite lamb cu...</td>\n",
       "      <td>0.279545</td>\n",
       "      <td>0.713068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>JrIxlS1TzJ-iCu79ul40cQ</td>\n",
       "      <td>eUta8W_HdHMXPzLBBZhL1A</td>\n",
       "      <td>04UD14gamNjLY0IDYVhHJg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>I am a long term frequent customer of this est...</td>\n",
       "      <td>2015-09-23 23:10:31</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>341</td>\n",
       "      <td>79</td>\n",
       "      <td>10</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>long term frequent customer establishment went...</td>\n",
       "      <td>0.211111</td>\n",
       "      <td>0.405556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>_ZeMknuYdlQcUqng_Im3yg</td>\n",
       "      <td>yfFzsLmaWF2d4Sr0UNbBgg</td>\n",
       "      <td>LHSTtnW3YHCeUkRDGyJOyw</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Amazingly amazing wings and homemade bleu chee...</td>\n",
       "      <td>2015-08-07 02:29:16</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>16</td>\n",
       "      <td>192</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>amazingly amazing wings homemade bleu cheese r...</td>\n",
       "      <td>0.505556</td>\n",
       "      <td>0.788889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  KU_O5udG6zpxOg-VcAEodg  mh_-eMZ6K5RLWhZyISBhwA  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
       "1  BiTunyQ73aT9WBnpR9DZGw  OyoGAe7OKpv6SyGZT5g77Q  7ATYjTIgM3jUlt4UM3IypQ   \n",
       "3  AqPFMleE6RsU23_auESxiA  _7bHUi9Uuf5__HHc_Q8guQ  kxX2SOes4o-D3ZQBkiMRfA   \n",
       "5  JrIxlS1TzJ-iCu79ul40cQ  eUta8W_HdHMXPzLBBZhL1A  04UD14gamNjLY0IDYVhHJg   \n",
       "7  _ZeMknuYdlQcUqng_Im3yg  yfFzsLmaWF2d4Sr0UNbBgg  LHSTtnW3YHCeUkRDGyJOyw   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "0    3.0       0      0     0   \n",
       "1    5.0       1      0     1   \n",
       "3    5.0       1      0     1   \n",
       "5    1.0       1      2     1   \n",
       "7    5.0       2      0     0   \n",
       "\n",
       "                                                text                date  \\\n",
       "0  If you decide to eat here, just be aware it is... 2018-07-07 22:09:11   \n",
       "1  I've taken a lot of spin classes over the year... 2012-01-03 15:28:18   \n",
       "3  Wow!  Yummy, different,  delicious.   Our favo... 2015-01-04 00:01:03   \n",
       "5  I am a long term frequent customer of this est... 2015-09-23 23:10:31   \n",
       "7  Amazingly amazing wings and homemade bleu chee... 2015-08-07 02:29:16   \n",
       "\n",
       "   year  ...  hour  min  sec  length_of_reviews  num_of_words  \\\n",
       "0  2018  ...    22    9   11                513           114   \n",
       "1  2012  ...    15   28   18                829           174   \n",
       "3  2015  ...     0    1    3                243            56   \n",
       "5  2015  ...    23   10   31                341            79   \n",
       "7  2015  ...     2   29   16                192            34   \n",
       "\n",
       "   num_of_sentences  capital_words_ratio  \\\n",
       "0                 7             0.026316   \n",
       "1                 7             0.011494   \n",
       "3                 6             0.000000   \n",
       "5                10             0.063291   \n",
       "7                 4             0.029412   \n",
       "\n",
       "                                        cleaned_text  sentiment_polarity  \\\n",
       "0  decide eat aware going take hours beginning en...            0.209722   \n",
       "1  ive taken lot spin classes years nothing compa...            0.395455   \n",
       "3  wow yummy different delicious favorite lamb cu...            0.279545   \n",
       "5  long term frequent customer establishment went...            0.211111   \n",
       "7  amazingly amazing wings homemade bleu cheese r...            0.505556   \n",
       "\n",
       "  sentiment_subjectivity  \n",
       "0               0.419444  \n",
       "1               0.571212  \n",
       "3               0.713068  \n",
       "5               0.405556  \n",
       "7               0.788889  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7399c04398ef7ffe93a346b34aea79387e9589ac40b89ce439d1cc4615c19a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
